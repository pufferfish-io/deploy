name: ðŸš€ Deploy Kafka (KRaft, single node)

on:
  workflow_dispatch:

jobs:
  deploy:
    name: ðŸ”„ Deploy Kafka (KRaft) into K3s
    runs-on: self-hosted

    env:
      # K3s kubeconfig path used across existing workflows
      KUBECONFIG: /etc/rancher/k3s/k3s.yaml

    steps:
      - name: ðŸ§¾ Checkout repo
        uses: actions/checkout@v4

      - name: ðŸ”§ Ensure namespace
        run: |
          # Idempotent: create namespace only if it does not exist
          kubectl get ns app || kubectl create ns app

      - name: ðŸ“¦ Apply Kafka manifest (StatefulSet + Service)
        run: |
          set -euo pipefail

          # Create a temporary manifest with inline comments and resource limits
          cat > /tmp/kafka.yaml <<'YAML'
          # Namespace is applied to be selfâ€‘contained; safe if already exists
          apiVersion: v1
          kind: Namespace
          metadata:
            name: app
          ---
          # ClusterIP Service for clients (Kafka API 9092)
          apiVersion: v1
          kind: Service
          metadata:
            name: kafka
            namespace: app
            labels:
              app: kafka
          spec:
            type: ClusterIP
            selector:
              app: kafka
            ports:
              - name: kafka
                port: 9092
                targetPort: 9092
          ---
          # Headless Service for stable pod DNS
          apiVersion: v1
          kind: Service
          metadata:
            name: kafka-headless
            namespace: app
            labels:
              app: kafka
          spec:
            clusterIP: None
            publishNotReadyAddresses: true
            selector:
              app: kafka
            ports:
              - name: controller
                port: 9093
                targetPort: 9093
          ---
          # Singleâ€‘replica Kafka (KRaft) with light limits; inter-broker PLAINTEXT; client SASL/SCRAM512
          apiVersion: apps/v1
          kind: StatefulSet
          metadata:
            name: kafka
            namespace: app
            labels:
              app: kafka
          spec:
            serviceName: kafka
            replicas: 1
            selector:
              matchLabels:
                app: kafka
            template:
              metadata:
                labels:
                  app: kafka
              spec:
                terminationGracePeriodSeconds: 30
                securityContext:
                  fsGroup: 1001
                initContainers:
                  - name: format-storage
                    image: apache/kafka:3.8.0
                    command: ["/bin/sh","-lc"]
                    args:
                      - |
                        set -e
                        cd /opt/kafka
                        if [ ! -f /var/lib/kafka/data/meta.properties ]; then
                          CID=$(bin/kafka-storage.sh random-uuid)
                          echo "Formatting storage with CLUSTER_ID=$CID"
                          bin/kafka-storage.sh format -t "$CID" -c config/kraft/server.properties
                        else
                          echo "Storage already formatted"
                        fi
                    volumeMounts:
                      - name: data
                        mountPath: /var/lib/kafka/data
                containers:
                  - name: kafka
                    image: apache/kafka:3.8.0
                    imagePullPolicy: IfNotPresent
                    env:
                      # KRaft single-node
                      - name: KAFKA_CFG_PROCESS_ROLES
                        value: broker,controller
                      - name: KAFKA_CFG_NODE_ID
                        value: "1"
                      - name: KAFKA_CFG_CONTROLLER_QUORUM_VOTERS
                        value: "1@kafka-0.kafka-headless.app.svc.cluster.local:9093"
                      - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES
                        value: CONTROLLER

                      # Listeners: INTERNAL for clients (SASL_PLAINTEXT), ADMIN for local admin (PLAINTEXT), CONTROLLER for KRaft
                      - name: KAFKA_CFG_LISTENERS
                        value: INTERNAL://:9092,CONTROLLER://:9093,ADMIN://:9094
                      - name: KAFKA_CFG_ADVERTISED_LISTENERS
                        value: INTERNAL://kafka.app.svc.cluster.local:9092,ADMIN://kafka-0.kafka-headless.app.svc.cluster.local:9094
                      - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
                        value: INTERNAL:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT,ADMIN:PLAINTEXT

                      # Use ADMIN (PLAINTEXT) for inter-broker
                      - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
                        value: ADMIN

                      # Client SASL settings (for INTERNAL listener only)
                      - name: KAFKA_CFG_SASL_ENABLED_MECHANISMS
                        value: SCRAM-SHA-512
                      - name: KAFKA_CFG_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS
                        value: SCRAM-SHA-512

                      # Single node replication factors
                      - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
                        value: "1"
                      - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
                        value: "1"
                      - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
                        value: "1"

                      # Data dir and light retention
                      - name: KAFKA_CFG_LOG_DIRS
                        value: "/var/lib/kafka/data"
                      - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
                        value: "true"
                      - name: KAFKA_CFG_NUM_PARTITIONS
                        value: "1"
                      - name: KAFKA_CFG_LOG_RETENTION_HOURS
                        value: "24"
                      - name: KAFKA_CFG_LOG_RETENTION_BYTES
                        value: "268435456"

                      # JVM heap smaller to avoid OOM spikes on 1Gi node
                      - name: KAFKA_HEAP_OPTS
                        value: "-Xmx192m -Xms192m"
                    ports:
                      - containerPort: 9092
                        name: kafka
                      - containerPort: 9093
                        name: controller
                      - containerPort: 9094
                        name: admin
                    volumeMounts:
                      - name: data
                        mountPath: /var/lib/kafka/data
                    resources:
                      requests:
                        cpu: 200m
                        memory: 384Mi
                      limits:
                        cpu: 500m
                        memory: 640Mi
            volumeClaimTemplates:
              - metadata:
                  name: data
                spec:
                  accessModes: ["ReadWriteOnce"]
                  storageClassName: local-path
                  resources:
                    requests:
                      storage: 5Gi
          YAML

          # Apply manifest idempotently
          kubectl apply -f /tmp/kafka.yaml

          # Ensure the image tag is exactly what we want (avoid stale tag in template)
          kubectl -n app set image statefulset/kafka kafka=apache/kafka:3.8.0 --record

      - name: ðŸ”Ž Rollout with live watch (pods + logs)
        run: |
          set -euo pipefail
          # Background live views limited by timeout; rollout runs in foreground
          POD="$(kubectl -n app get pod -l app=kafka -o jsonpath='{.items[0].metadata.name}' || true)"
          if [ -n "$POD" ]; then
            ( timeout 420s kubectl -n app logs -f "$POD" || true ) &
            LOG_PID=$!
            ( timeout 420s kubectl -n app get pods -l app=kafka -w || true ) &
            WATCH_PID=$!
          fi

          ROLLOUT_RC=0
          kubectl -n app rollout status statefulset/kafka --timeout=420s || ROLLOUT_RC=$?
          kubectl -n app get pods -l app=kafka -o wide || true

          # Cleanup background watchers
          if [ -n "${LOG_PID:-}" ]; then kill "$LOG_PID" 2>/dev/null || true; wait "$LOG_PID" 2>/dev/null || true; fi
          if [ -n "${WATCH_PID:-}" ]; then kill "$WATCH_PID" 2>/dev/null || true; wait "$WATCH_PID" 2>/dev/null || true; fi

          # If rollout failed, show recent events for faster diagnosis
          if [ "$ROLLOUT_RC" -ne 0 ] && [ -n "$POD" ]; then
            echo "--- Pod events (tail) ---"
            kubectl -n app describe pod "$POD" | sed -n '/Events/,$p' || true
            exit "$ROLLOUT_RC"
          fi

      - name: ðŸ“£ Summary
        run: |
          echo "Bootstrap for services: kafka.app.svc.cluster.local:9092"
          echo "Ensure repo Variables are set for topic names and group/client IDs."
