name: ðŸš€ Deploy Kafka (KRaft, single node)

on:
  workflow_dispatch:

jobs:
  deploy:
    name: ðŸ”„ Deploy Kafka (KRaft) into K3s
    runs-on: self-hosted

    env:
      # K3s kubeconfig path used across existing workflows
      KUBECONFIG: /etc/rancher/k3s/k3s.yaml

    steps:
      - name: ðŸ§¾ Checkout repo
        uses: actions/checkout@v4

      - name: ðŸ”§ Ensure namespace
        run: |
          # Idempotent: create namespace only if it does not exist
          kubectl get ns app || kubectl create ns app

      - name: ðŸ“¦ Apply Kafka manifest (StatefulSet + Service)
        run: |
          set -euo pipefail

          # Create a temporary manifest with inline comments and resource limits
          cat > /tmp/kafka.yaml <<'YAML'
          # Namespace is applied to be selfâ€‘contained; safe if already exists
          apiVersion: v1
          kind: Namespace
          metadata:
            name: app
          ---
          # ClusterIP Service for clients (Kafka API 9092)
          apiVersion: v1
          kind: Service
          metadata:
            name: kafka
            namespace: app
            labels:
              app: kafka
          spec:
            type: ClusterIP
            selector:
              app: kafka
            ports:
              - name: kafka
                port: 9092
                targetPort: 9092
          ---
          # Headless Service for stable pod DNS
          apiVersion: v1
          kind: Service
          metadata:
            name: kafka-headless
            namespace: app
            labels:
              app: kafka
          spec:
            clusterIP: None
            publishNotReadyAddresses: true
            selector:
              app: kafka
            ports:
              - name: controller
                port: 9093
                targetPort: 9093
          ---
          # Singleâ€‘replica Kafka (KRaft) with light limits; inter-broker PLAINTEXT; client SASL/SCRAM512
          apiVersion: apps/v1
          kind: StatefulSet
          metadata:
            name: kafka
            namespace: app
            labels:
              app: kafka
          spec:
            # IMPORTANT: use headless service for stable per-pod DNS (kafka-0.kafka-headless...)
            serviceName: kafka-headless
            replicas: 1
            selector:
              matchLabels:
                app: kafka
            template:
              metadata:
                labels:
                  app: kafka
              spec:
                terminationGracePeriodSeconds: 30
                securityContext:
                  fsGroup: 1001
                initContainers:
                  - name: generate-config
                    image: apache/kafka:3.8.0
                    command: ["/bin/sh","-lc"]
                    args:
                      - |
                        set -e
                        cat > /etc/kafka/server.properties << 'EOF'
                        process.roles=broker,controller
                        node.id=1
                        controller.quorum.voters=1@kafka-0.kafka-headless.app.svc.cluster.local:9093
                        listeners=INTERNAL://:9092,CONTROLLER://:9093,ADMIN://:9094
                        advertised.listeners=INTERNAL://kafka.app.svc.cluster.local:9092,ADMIN://kafka-0.kafka-headless.app.svc.cluster.local:9094
                        listener.security.protocol.map=INTERNAL:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT,ADMIN:PLAINTEXT
                        inter.broker.listener.name=ADMIN
                        num.partitions=1
                        auto.create.topics.enable=true
                        log.dirs=/var/lib/kafka/data
                        log.retention.hours=24
                        log.retention.bytes=268435456
                        offsets.topic.replication.factor=1
                        transaction.state.log.replication.factor=1
                        transaction.state.log.min.isr=1
                        sasl.enabled.mechanisms=SCRAM-SHA-512
                        listener.name.internal.sasl.enabled.mechanisms=SCRAM-SHA-512
                        EOF
                    volumeMounts:
                      - name: config
                        mountPath: /etc/kafka
                  - name: format-storage
                    image: apache/kafka:3.8.0
                    command: ["/bin/sh","-lc"]
                    args:
                      - |
                        set -e
                        cd /opt/kafka
                        if [ ! -f /var/lib/kafka/data/meta.properties ]; then
                          CID=$(bin/kafka-storage.sh random-uuid)
                          echo "Formatting storage with CLUSTER_ID=$CID"
                          bin/kafka-storage.sh format -t "$CID" -c /etc/kafka/server.properties
                        else
                          echo "Storage already formatted"
                        fi
                    volumeMounts:
                      - name: data
                        mountPath: /var/lib/kafka/data
                containers:
                  - name: kafka
                    image: apache/kafka:3.8.0
                    imagePullPolicy: IfNotPresent
                    # Explicitly start server with generated KRaft config
                    command: ["/bin/sh","-lc"]
                    args: ["/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties"]
                    env:
                      - name: KAFKA_HEAP_OPTS
                        value: "-Xmx192m -Xms192m"
                    ports:
                      - containerPort: 9092
                        name: kafka
                      - containerPort: 9093
                        name: controller
                      - containerPort: 9094
                        name: admin
                    volumeMounts:
                      - name: data
                        mountPath: /var/lib/kafka/data
                      - name: config
                        mountPath: /etc/kafka
                    resources:
                      requests:
                        cpu: 200m
                        memory: 384Mi
                      limits:
                        cpu: 500m
                        memory: 640Mi
            volumeClaimTemplates:
              - metadata:
                  name: data
                spec:
                  accessModes: ["ReadWriteOnce"]
                  storageClassName: local-path
                  resources:
                    requests:
                      storage: 5Gi
            # extra volumes
            # (emptyDir used to hold generated server.properties)
            # Note: volumeClaimTemplates above defines persistent data volume
            # for /var/lib/kafka/data
          ---
          apiVersion: v1
          kind: Pod
          metadata:
            name: placeholder-do-not-create
          spec:
            volumes:
            - name: config
              emptyDir: {}
          # This placeholder defines volume schema; actual volumes are embedded in StatefulSet via same name
          YAML

          # Apply manifest idempotently
          kubectl apply -f /tmp/kafka.yaml

          # Ensure the image tag is exactly what we want (avoid stale tag in template)
          kubectl -n app set image statefulset/kafka kafka=apache/kafka:3.8.0 --record

      - name: ðŸ”Ž Rollout with live watch (pods + logs)
        run: |
          set -euo pipefail
          # Background live views limited by timeout; rollout runs in foreground
          POD="$(kubectl -n app get pod -l app=kafka -o jsonpath='{.items[0].metadata.name}' || true)"
          if [ -n "$POD" ]; then
            ( timeout 420s kubectl -n app logs -f "$POD" || true ) &
            LOG_PID=$!
            ( timeout 420s kubectl -n app get pods -l app=kafka -w || true ) &
            WATCH_PID=$!
          fi

          ROLLOUT_RC=0
          kubectl -n app rollout status statefulset/kafka --timeout=420s || ROLLOUT_RC=$?
          kubectl -n app get pods -l app=kafka -o wide || true

          # Cleanup background watchers
          if [ -n "${LOG_PID:-}" ]; then kill "$LOG_PID" 2>/dev/null || true; wait "$LOG_PID" 2>/dev/null || true; fi
          if [ -n "${WATCH_PID:-}" ]; then kill "$WATCH_PID" 2>/dev/null || true; wait "$WATCH_PID" 2>/dev/null || true; fi

          # If rollout failed, show recent events for faster diagnosis
          if [ "$ROLLOUT_RC" -ne 0 ] && [ -n "$POD" ]; then
            echo "--- Pod events (tail) ---"
            kubectl -n app describe pod "$POD" | sed -n '/Events/,$p' || true
            exit "$ROLLOUT_RC"
          fi

      - name: ðŸ“£ Summary
        run: |
          echo "Bootstrap for services: kafka.app.svc.cluster.local:9092"
          echo "Ensure repo Variables are set for topic names and group/client IDs."
